input {
  beats {
    port => 5044
    codec => "plain"   # 先按纯文本读，不强行解析
  }
}


filter {
     # 在所有处理前打印完整事件结构
     ruby {
       code => "
         puts '[DEBUG] === BEFORE FILTER ==='
         # puts JSON.pretty_generate(event.to_hash)
         puts event.to_hash.inspect
         puts '[DEBUG] ====================='
       "
     }

  # 只处理 order-service 的日志
  if [container][labels][com_docker_compose_service] == "order-service" {

    # 使用 grok 解析 Spring Boot 标准日志格式
    grok {
      match => {
        "message" => "%{TIMESTAMP_ISO8601:app.timestamp}  %{LOGLEVEL:app.level} %{NUMBER:app.pid} --- \[%{DATA:app.application}\] \[%{DATA:app.thread}\] \[%{DATA:app.traceId}\] %{JAVACLASS:app.class} *: %{GREEDYDATA:app.message}"
      }
      overwrite => ["message"]  # 把解析后的内容覆盖原 message
      tag_on_failure => ["grok-failure"]
    }

    # 如果解析成功，打标签并清理无用字段
    if "grok-failure" not in [tags] {
      mutate {
        add_tag => ["parsed-success"]
        remove_field => [
          "agent",
          "input",
          "host",
          "ecs",
          "log",
          "stream",
          "container"
          # 不支持点分路径删除
          #"container.id",
          #"container.image.name",
          #"container.labels.filebeat_enable"
        ]
      }
    } else {
      mutate {
        add_tag => ["parsed-failed"]
      }
    }

    # 时间拟合
    date {
      match => [ "app.timestamp", "ISO8601" ]
      target => "@timestamp"
    }
  }
}


output {
  #stdout { codec => rubydebug }

  if "parsed-success" in [tags] {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "app-logs-%{+YYYY.MM.dd}"
      document_type => "_doc"
      template_overwrite => true
    }
  }

}